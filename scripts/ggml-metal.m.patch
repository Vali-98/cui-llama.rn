--- ggml-metal-orig.m	2023-08-27 12:32:10
+++ ggml-metal.m	2023-08-27 12:32:47
@@ -5,6 +5,7 @@
 #import <Foundation/Foundation.h>

 #import <Metal/Metal.h>
+#import <MetalPerformanceShaders/MetalPerformanceShaders.h>

 #undef MIN
 #undef MAX
@@ -80,15 +81,15 @@
     LM_GGML_METAL_DECL_KERNEL(mul_mat_q4_K_f32);
     LM_GGML_METAL_DECL_KERNEL(mul_mat_q5_K_f32);
     LM_GGML_METAL_DECL_KERNEL(mul_mat_q6_K_f32);
-    LM_GGML_METAL_DECL_KERNEL(mul_mm_f16_f32);
-    LM_GGML_METAL_DECL_KERNEL(mul_mm_q4_0_f32);
-    LM_GGML_METAL_DECL_KERNEL(mul_mm_q4_1_f32);
-    LM_GGML_METAL_DECL_KERNEL(mul_mm_q8_0_f32);
-    LM_GGML_METAL_DECL_KERNEL(mul_mm_q2_K_f32);
-    LM_GGML_METAL_DECL_KERNEL(mul_mm_q3_K_f32);
-    LM_GGML_METAL_DECL_KERNEL(mul_mm_q4_K_f32);
-    LM_GGML_METAL_DECL_KERNEL(mul_mm_q5_K_f32);
-    LM_GGML_METAL_DECL_KERNEL(mul_mm_q6_K_f32);
+    // LM_GGML_METAL_DECL_KERNEL(mul_mm_f16_f32);
+    // LM_GGML_METAL_DECL_KERNEL(mul_mm_q4_0_f32);
+    // LM_GGML_METAL_DECL_KERNEL(mul_mm_q4_1_f32);
+    // LM_GGML_METAL_DECL_KERNEL(mul_mm_q8_0_f32);
+    // LM_GGML_METAL_DECL_KERNEL(mul_mm_q2_K_f32);
+    // LM_GGML_METAL_DECL_KERNEL(mul_mm_q3_K_f32);
+    // LM_GGML_METAL_DECL_KERNEL(mul_mm_q4_K_f32);
+    // LM_GGML_METAL_DECL_KERNEL(mul_mm_q5_K_f32);
+    // LM_GGML_METAL_DECL_KERNEL(mul_mm_q6_K_f32);
     LM_GGML_METAL_DECL_KERNEL(rope);
     LM_GGML_METAL_DECL_KERNEL(alibi_f32);
     LM_GGML_METAL_DECL_KERNEL(cpy_f32_f16);
@@ -141,7 +142,7 @@

         //NSString * path = [[NSBundle mainBundle] pathForResource:@"../../examples/metal/metal" ofType:@"metal"];
         NSBundle * bundle = [NSBundle bundleForClass:[GGMLMetalClass class]];
-        NSString * path = [bundle pathForResource:@"ggml-metal" ofType:@"metal"];
+        NSString * path = [bundle pathForResource:@"ggml-metal-qk_no_simd" ofType:@"metal"];
         fprintf(stderr, "%s: loading '%s'\n", __func__, [path UTF8String]);

         NSString * src  = [NSString stringWithContentsOfFile:path encoding:NSUTF8StringEncoding error:&error];
@@ -208,15 +209,15 @@
         LM_GGML_METAL_ADD_KERNEL(mul_mat_q4_K_f32);
         LM_GGML_METAL_ADD_KERNEL(mul_mat_q5_K_f32);
         LM_GGML_METAL_ADD_KERNEL(mul_mat_q6_K_f32);
-        LM_GGML_METAL_ADD_KERNEL(mul_mm_f16_f32);
-        LM_GGML_METAL_ADD_KERNEL(mul_mm_q4_0_f32);
-        LM_GGML_METAL_ADD_KERNEL(mul_mm_q8_0_f32);
-        LM_GGML_METAL_ADD_KERNEL(mul_mm_q4_1_f32);
-        LM_GGML_METAL_ADD_KERNEL(mul_mm_q2_K_f32);
-        LM_GGML_METAL_ADD_KERNEL(mul_mm_q3_K_f32);
-        LM_GGML_METAL_ADD_KERNEL(mul_mm_q4_K_f32);
-        LM_GGML_METAL_ADD_KERNEL(mul_mm_q5_K_f32);
-        LM_GGML_METAL_ADD_KERNEL(mul_mm_q6_K_f32);
+        // LM_GGML_METAL_ADD_KERNEL(mul_mm_f16_f32);
+        // LM_GGML_METAL_ADD_KERNEL(mul_mm_q4_0_f32);
+        // LM_GGML_METAL_ADD_KERNEL(mul_mm_q8_0_f32);
+        // LM_GGML_METAL_ADD_KERNEL(mul_mm_q4_1_f32);
+        // LM_GGML_METAL_ADD_KERNEL(mul_mm_q2_K_f32);
+        // LM_GGML_METAL_ADD_KERNEL(mul_mm_q3_K_f32);
+        // LM_GGML_METAL_ADD_KERNEL(mul_mm_q4_K_f32);
+        // LM_GGML_METAL_ADD_KERNEL(mul_mm_q5_K_f32);
+        // LM_GGML_METAL_ADD_KERNEL(mul_mm_q6_K_f32);
         LM_GGML_METAL_ADD_KERNEL(rope);
         LM_GGML_METAL_ADD_KERNEL(alibi_f32);
         LM_GGML_METAL_ADD_KERNEL(cpy_f32_f16);
@@ -226,13 +227,13 @@
 #undef LM_GGML_METAL_ADD_KERNEL
     }

-    fprintf(stderr, "%s: recommendedMaxWorkingSetSize  = %8.2f MB\n", __func__, ctx->device.recommendedMaxWorkingSetSize / 1024.0 / 1024.0);
-    fprintf(stderr, "%s: hasUnifiedMemory              = %s\n",       __func__, ctx->device.hasUnifiedMemory ? "true" : "false");
-    if (ctx->device.maxTransferRate != 0) {
-        fprintf(stderr, "%s: maxTransferRate               = %8.2f MB/s\n", __func__, ctx->device.maxTransferRate / 1024.0 / 1024.0);
-    } else {
-        fprintf(stderr, "%s: maxTransferRate               = built-in GPU\n", __func__);
-    }
+    // fprintf(stderr, "%s: recommendedMaxWorkingSetSize  = %8.2f MB\n", __func__, ctx->device.recommendedMaxWorkingSetSize / 1024.0 / 1024.0);
+    // fprintf(stderr, "%s: hasUnifiedMemory              = %s\n",       __func__, ctx->device.hasUnifiedMemory ? "true" : "false");
+    // if (ctx->device.maxTransferRate != 0) {
+    //     fprintf(stderr, "%s: maxTransferRate               = %8.2f MB/s\n", __func__, ctx->device.maxTransferRate / 1024.0 / 1024.0);
+    // } else {
+    //     fprintf(stderr, "%s: maxTransferRate               = built-in GPU\n", __func__);
+    // }

     return ctx;
 }
@@ -374,15 +375,15 @@
             }
         }

-        fprintf(stderr, ", (%8.2f / %8.2f)",
-                ctx->device.currentAllocatedSize / 1024.0 / 1024.0,
-                ctx->device.recommendedMaxWorkingSetSize / 1024.0 / 1024.0);
+        // fprintf(stderr, ", (%8.2f / %8.2f)",
+        //         ctx->device.currentAllocatedSize / 1024.0 / 1024.0,
+        //         ctx->device.recommendedMaxWorkingSetSize / 1024.0 / 1024.0);

-        if (ctx->device.currentAllocatedSize > ctx->device.recommendedMaxWorkingSetSize) {
-            fprintf(stderr, ", warning: current allocated size is greater than the recommended max working set size\n");
-        } else {
-            fprintf(stderr, "\n");
-        }
+        // if (ctx->device.currentAllocatedSize > ctx->device.recommendedMaxWorkingSetSize) {
+        //     fprintf(stderr, ", warning: current allocated size is greater than the recommended max working set size\n");
+        // } else {
+        //     fprintf(stderr, "\n");
+        // }
     }

     return true;
@@ -737,46 +738,51 @@
                         } break;
                     case LM_GGML_OP_MUL_MAT:
                         {
-                            // TODO: needs to be updated after PR: https://github.com/ggerganov/ggml/pull/224
-
                             LM_GGML_ASSERT(ne00 == ne10);
-                            // LM_GGML_ASSERT(ne02 == ne12); // Should be checked on individual data types until broadcast is implemented everywhere
-                            uint gqa = ne12/ne02;
-                            LM_GGML_ASSERT(ne03 == ne13);
+                            LM_GGML_ASSERT(ne02 == ne12);

                             // for now the matrix-matrix multiplication kernel only works on A14+/M1+ SoCs
                             // AMD GPU and older A-chips will reuse matrix-vector multiplication kernel
                             if (lm_ggml_is_contiguous(src0) &&
                                 lm_ggml_is_contiguous(src1) &&
-                                src1t == LM_GGML_TYPE_F32 &&
-                                [ctx->device supportsFamily:MTLGPUFamilyApple7] &&
-                                ne00%32 == 0 &&
-                                ne11 > 1) {
-                                switch (src0->type) {
-                                    case LM_GGML_TYPE_F16:  [encoder setComputePipelineState:ctx->pipeline_mul_mm_f16_f32];  break;
-                                    case LM_GGML_TYPE_Q4_0: [encoder setComputePipelineState:ctx->pipeline_mul_mm_q4_0_f32]; break;
-                                    case LM_GGML_TYPE_Q4_1: [encoder setComputePipelineState:ctx->pipeline_mul_mm_q4_1_f32]; break;
-                                    case LM_GGML_TYPE_Q8_0: [encoder setComputePipelineState:ctx->pipeline_mul_mm_q8_0_f32]; break;
-                                    case LM_GGML_TYPE_Q2_K: [encoder setComputePipelineState:ctx->pipeline_mul_mm_q2_K_f32]; break;
-                                    case LM_GGML_TYPE_Q3_K: [encoder setComputePipelineState:ctx->pipeline_mul_mm_q3_K_f32]; break;
-                                    case LM_GGML_TYPE_Q4_K: [encoder setComputePipelineState:ctx->pipeline_mul_mm_q4_K_f32]; break;
-                                    case LM_GGML_TYPE_Q5_K: [encoder setComputePipelineState:ctx->pipeline_mul_mm_q5_K_f32]; break;
-                                    case LM_GGML_TYPE_Q6_K: [encoder setComputePipelineState:ctx->pipeline_mul_mm_q6_K_f32]; break;
-                                    default: LM_GGML_ASSERT(false && "MUL MAT-MAT not implemented");
+                                (src0t == LM_GGML_TYPE_F32 || src0t == LM_GGML_TYPE_F16) && ne11 > 1) {
+
+                                if (encoder != nil) {
+                                    [encoder endEncoding];
+                                    encoder = nil;
                                 }
-                                [encoder setBuffer:id_src0 offset:offs_src0    atIndex:0];
-                                [encoder setBuffer:id_src1 offset:offs_src1    atIndex:1];
-                                [encoder setBuffer:id_dst  offset:offs_dst     atIndex:2];
-                                [encoder setBytes:&ne00    length:sizeof(ne00) atIndex:3];
-                                [encoder setBytes:&ne02    length:sizeof(ne02) atIndex:4];
-                                [encoder setBytes:&nb01    length:sizeof(nb01) atIndex:5];
-                                [encoder setBytes:&nb02    length:sizeof(nb02) atIndex:6];
-                                [encoder setBytes:&ne12    length:sizeof(ne12) atIndex:7];
-                                [encoder setBytes:&ne0     length:sizeof(ne0)  atIndex:8];
-                                [encoder setBytes:&ne1     length:sizeof(ne1)  atIndex:9];
-                                [encoder setBytes:&gqa     length:sizeof(gqa)  atIndex:10];
-                                [encoder setThreadgroupMemoryLength:8192 atIndex:0];
-                                [encoder dispatchThreadgroups:MTLSizeMake( (ne11+31)/32, (ne01+63) / 64, ne12) threadsPerThreadgroup:MTLSizeMake(128, 1, 1)];
+
+                                MPSDataType src0dt = src0t == LM_GGML_TYPE_F32 ? MPSDataTypeFloat32 : MPSDataTypeFloat16;
+                                MPSDataType src1dt = src1t == LM_GGML_TYPE_F32 ? MPSDataTypeFloat32 : MPSDataTypeFloat16;
+
+                                // for F32 x F32 we use MPS
+                                MPSMatrixDescriptor * desc0 = [MPSMatrixDescriptor
+                                    matrixDescriptorWithRows:ne01 columns:ne00 rowBytes:src0->nb[1] dataType:src0dt];
+
+                                MPSMatrixDescriptor * desc1 = [MPSMatrixDescriptor
+                                    matrixDescriptorWithRows:ne11 columns:ne10 rowBytes:src1->nb[1] dataType:src1dt];
+
+                                MPSMatrixDescriptor * desc  = [MPSMatrixDescriptor
+                                    matrixDescriptorWithRows:ne1 columns:ne0 rowBytes:dst->nb[1] dataType:MPSDataTypeFloat32];
+
+                                MPSMatrixMultiplication * mul = [[MPSMatrixMultiplication alloc]
+                                    initWithDevice:ctx->device transposeLeft:false transposeRight:true
+                                        resultRows:ne11 resultColumns:ne01 interiorColumns:ne00 alpha:1.0 beta:0.0];
+
+                                // we need to do ne02 multiplications
+                                // TODO: is there a way to do this in parallel - currently very slow ..
+                                // TODO: might be possible to offload part of the computation to ANE using Accelerate's CBLAS
+                                for (int64_t i02 = 0; i02 < ne02; ++i02) {
+                                    size_t offs_src0_cur = offs_src0 + i02*nb02;
+                                    size_t offs_src1_cur = offs_src1 + i02*nb12;
+                                    size_t offs_dst_cur  = offs_dst  + i02*nb2;
+
+                                    MPSMatrix * mat_src0 = [[MPSMatrix alloc] initWithBuffer:id_src0 offset:offs_src0_cur descriptor:desc0];
+                                    MPSMatrix * mat_src1 = [[MPSMatrix alloc] initWithBuffer:id_src1 offset:offs_src1_cur descriptor:desc1];
+                                    MPSMatrix * mat_dst  = [[MPSMatrix alloc] initWithBuffer:id_dst  offset:offs_dst_cur  descriptor:desc ];
+
+                                    [mul encodeToCommandBuffer:command_buffer leftMatrix:mat_src1 rightMatrix:mat_src0 resultMatrix:mat_dst];
+                                }
                             } else {
                                 int nth0 = 32;
                                 int nth1 = 1;
@@ -821,8 +827,8 @@
                                             LM_GGML_ASSERT(ne02 == 1);
                                             LM_GGML_ASSERT(ne12 == 1);

-                                            nth0 = 2;
-                                            nth1 = 32;
+                                            nth0 = 4;
+                                            nth1 = 16;
                                             [encoder setComputePipelineState:ctx->pipeline_mul_mat_q2_K_f32];
                                         } break;
                                     case LM_GGML_TYPE_Q3_K:
@@ -839,8 +845,8 @@
                                             LM_GGML_ASSERT(ne02 == 1);
                                             LM_GGML_ASSERT(ne12 == 1);

-                                            nth0 = 2;
-                                            nth1 = 32;
+                                            nth0 = 4;
+                                            nth1 = 16;
                                             [encoder setComputePipelineState:ctx->pipeline_mul_mat_q4_K_f32];
                                         } break;
                                     case LM_GGML_TYPE_Q5_K:
@@ -857,8 +863,8 @@
                                             LM_GGML_ASSERT(ne02 == 1);
                                             LM_GGML_ASSERT(ne12 == 1);

-                                            nth0 = 2;
-                                            nth1 = 32;
+                                            nth0 = 4;
+                                            nth1 = 16;
                                             [encoder setComputePipelineState:ctx->pipeline_mul_mat_q6_K_f32];
                                         } break;
                                     default:
@@ -885,10 +891,12 @@
                                 [encoder setBytes:&nb12 length:sizeof(nb12) atIndex:14];
                                 [encoder setBytes:&ne0  length:sizeof(ne0)  atIndex:15];
                                 [encoder setBytes:&ne1  length:sizeof(ne1)  atIndex:16];
-                                [encoder setBytes:&gqa  length:sizeof(gqa)  atIndex:17];
+//                                [encoder setBytes:&gqa  length:sizeof(gqa)  atIndex:17];

-                                if (src0t == LM_GGML_TYPE_Q4_0 || src0t == LM_GGML_TYPE_Q4_1 || src0t == LM_GGML_TYPE_Q8_0 ||
-                                    src0t == LM_GGML_TYPE_Q2_K || src0t == LM_GGML_TYPE_Q4_K) {
+                                if (src0t == LM_GGML_TYPE_Q2_K || src0t == LM_GGML_TYPE_Q6_K || src0t == LM_GGML_TYPE_Q4_K) {
+                                    [encoder setThreadgroupMemoryLength:nth0*nth1*sizeof(float) atIndex:0];
+                                    [encoder dispatchThreadgroups:MTLSizeMake(ne01, 1, 1) threadsPerThreadgroup:MTLSizeMake(nth0, nth1, 1)];
+                                } else if (src0t == LM_GGML_TYPE_Q4_0 || src0t == LM_GGML_TYPE_Q4_1 || src0t == LM_GGML_TYPE_Q8_0) {
                                     [encoder dispatchThreadgroups:MTLSizeMake((ne01 + 7)/8, ne11, ne12) threadsPerThreadgroup:MTLSizeMake(nth0, nth1, 1)];
                                 }
                                 else if (src0t == LM_GGML_TYPE_Q3_K) {
@@ -900,9 +908,6 @@
                                 }
                                 else if (src0t == LM_GGML_TYPE_Q5_K) {
                                     [encoder dispatchThreadgroups:MTLSizeMake((ne01 + 3)/4, ne11, ne12) threadsPerThreadgroup:MTLSizeMake(nth0, nth1, 1)];
-                                }
-                                else if (src0t == LM_GGML_TYPE_Q6_K) {
-                                    [encoder dispatchThreadgroups:MTLSizeMake((ne01 + 1)/2, ne11, ne12) threadsPerThreadgroup:MTLSizeMake(nth0, nth1, 1)];
                                 } else {
                                     [encoder setThreadgroupMemoryLength:nth0*sizeof(float) atIndex:0];
                                     [encoder dispatchThreadgroups:MTLSizeMake(ne01, ne11, ne12) threadsPerThreadgroup:MTLSizeMake(nth0, nth1, 1)];
@@ -937,10 +942,9 @@
                         } break;
                     case LM_GGML_OP_RMS_NORM:
                         {
-                            float eps;
-                            memcpy(&eps, dst->op_params, sizeof(float));
+                            const float eps = 1e-6f;

-                            const int nth = 512;
+                            const int nth = 256;

                             [encoder setComputePipelineState:ctx->pipeline_rms_norm];
                             [encoder setBuffer:id_src0 offset:offs_src0 atIndex:0];
@@ -948,7 +952,7 @@
                             [encoder setBytes:&ne00 length:sizeof( int64_t) atIndex:2];
                             [encoder setBytes:&nb01 length:sizeof(uint64_t) atIndex:3];
                             [encoder setBytes:&eps  length:sizeof(   float) atIndex:4];
-                            [encoder setThreadgroupMemoryLength:nth/32*sizeof(float) atIndex:0];
+                            [encoder setThreadgroupMemoryLength:nth*sizeof(float) atIndex:0];

                             const int64_t nrows = lm_ggml_nrows(src0);

