--- common.cpp.orig	2024-05-29 09:16:58
+++ common.cpp	2024-05-29 09:16:59
@@ -53,6 +53,12 @@
 #include <thread>
 #include <future>
 #endif
+
+// build info
+int LLAMA_BUILD_NUMBER = 0;
+char const *LLAMA_COMMIT = "unknown";
+char const *LLAMA_COMPILER = "unknown";
+char const *LLAMA_BUILD_TARGET = "unknown";

 #if defined(_MSC_VER)
 #pragma warning(disable: 4244 4267) // possible loss of data
@@ -2219,3 +2219,4 @@
    auto mparams = llama_model_default_params();

+   mparams.vocab_only      = params.vocab_only;
    if (params.n_gpu_layers != -1) {
    mparams.n_gpu_layers = params.n_gpu_layers;
